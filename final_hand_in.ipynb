{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting topology of transmembrane proteins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook serves as the final hand in for this project. Using a five-fold crossvalidation, the notebook will train a bidirectional neural network, hyperparameter optimise for the hidden number of units for the LSTM layer as well as number of layers via a validation set. Finally, the best model for each fold will be evaluated against a test set and the model performing best in the most folds will be chosen to visualise its results. The results include a loss curve, accuracy curves and a heat map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load modules\n",
    "from itertools import cycle, islice\n",
    "from cycler import cycler\n",
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
    "import numpy as np\n",
    "import json\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from typing import List, Union, Dict\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading of helper functions\n",
    "\n",
    "The following cells will load functions that are needed for the analysis itself. When the analysis took place, these functions were scattered across multiple .py files. They have now been gathered here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Early stopping\n",
    "Helper class for the early stopping implemented in the training loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"This code is from: https://github.com/Bjarten/early-stopping-pytorch/blob/master/MNIST_Early_Stopping_example.ipynb\n",
    "    However, the code has been adjusted to work for max accuracy as opposed to min loss\n",
    "    \n",
    "    Early stops the training if validation topology accuracy doesn't improve after some given patience.\"\"\"\n",
    "    \n",
    "    def __init__(self, patience = 7, verbose = False, delta = 0, path = 'checkpoint.pt', trace_func = print):\n",
    "        \"\"\"\n",
    "        args:\n",
    "            patience (int): how long to wait after last time improved validation accuracy.Default: 7\n",
    "            verbose (bool): if True, prints a message for each validation accuracy improvement. Default: False\n",
    "            delta (float): minimum change in monitored quantity to qualify as improvement. Default: 0\n",
    "            path (str): path for checkpoint save location. Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function. Default: print            \n",
    "        \"\"\"\n",
    "        \n",
    "        self.patience = patience\n",
    "        self.counter = 0\n",
    "        \n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "        self.verbose = verbose\n",
    "        \n",
    "        self.best_score = None\n",
    "        self.delta = delta\n",
    "        self.early_stop = False\n",
    "        self.val_acc_max = -np.Inf\n",
    "        \n",
    "    def __call__(self, val_acc, model):\n",
    "        score = -val_acc\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_acc, model)\n",
    "        \n",
    "        # changing the inequality such that the accuracy keeps getting better\n",
    "        elif score >= self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_acc, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_acc, model):\n",
    "        '''Saves model when validation accuracy increases.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(f'Validation accuracy increased ({self.val_acc_max:.6f} --> {val_acc:.6f}).  Saving model ...')\n",
    "            \n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_acc_max = val_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BRNN model\n",
    "Create NN class with hyperparameters as variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes, num_layer):\n",
    "        super(RNN, self).__init__()\n",
    "        \n",
    "        self.dropout = nn.Dropout(p = 0.2)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layer\n",
    "        # rnn\n",
    "        self.lstm = nn.LSTM(input_size = input_size, hidden_size = hidden_size, \n",
    "                            batch_first = True, bidirectional = True, num_layers = num_layer)\n",
    "\n",
    "        # define fully connected layers\n",
    "        self.linear = nn.Linear(hidden_size*2, num_classes, bias = False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # return output and last hidden state\n",
    "        x, (h, c) = self.lstm(self.dropout(x))\n",
    "        \n",
    "        # fully-connected output layer\n",
    "        x = self.linear(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accuracy computation function\n",
    "\n",
    "All functions necessary for calculating accuracy in accordance with DeepTMHMM. Code is provided by DeepTMHMM but have been slightly modified to suit our analysis setup: https://www.biorxiv.org/content/10.1101/2022.04.08.487609v1.full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_nested_dict(d, keys, value):\n",
    "    for idx, key in enumerate(keys[:-1]):\n",
    "        if key not in d:\n",
    "            d[key] = {}\n",
    "        d = d[key]\n",
    "    d[keys[-1]] = value\n",
    "\n",
    "def custom_encoder(obj):\n",
    "    if 'confusion_matrix' in obj:\n",
    "        return json.dumps(obj, separators=(',', ':'), indent=4)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def type_from_labels(label):\n",
    "    \"\"\"\n",
    "    Function that determines the protein type from labels\n",
    "\n",
    "    Dimension of each label:\n",
    "    (len_of_longenst_protein_in_batch)\n",
    "\n",
    "    # Residue class\n",
    "    0 = inside cell/cytosol (I)\n",
    "    1 = Outside cell/lumen of ER/Golgi/lysosomes (O)\n",
    "    2 = beta membrane (B)\n",
    "    3 = signal peptide (S)\n",
    "    4 = alpha membrane (M)\n",
    "    5 = periplasm (P)\n",
    "\n",
    "    B in the label sequence -> beta\n",
    "    I only -> globular\n",
    "    Both S and M -> SP + alpha(TM)\n",
    "    M -> alpha(TM)\n",
    "    S -> signal peptide\n",
    "\n",
    "    # Protein type class\n",
    "    0 = TM\n",
    "    1 = SP + TM\n",
    "    2 = SP\n",
    "    3 = GLOBULAR\n",
    "    4 = BETA\n",
    "    \"\"\"\n",
    "\n",
    "    if 2 in label:\n",
    "        ptype = 4\n",
    "\n",
    "    elif all(element == 0 for element in label):\n",
    "        ptype = 3\n",
    "\n",
    "    elif 3 in label and 4 in label:\n",
    "        ptype = 1\n",
    "\n",
    "    elif 3 in label:\n",
    "       ptype = 2\n",
    "\n",
    "    elif 4 in label:\n",
    "        ptype = 0\n",
    "\n",
    "    elif all(x == 0 or x == -1 for x in label):\n",
    "        ptype = 3\n",
    "\n",
    "    else:\n",
    "        ptype = None\n",
    "\n",
    "    return ptype\n",
    "\n",
    "def label_list_to_topology(labels: Union[List[int], torch.Tensor]) -> List[torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Converts a list of per-position labels to a topology representation.\n",
    "    This maps every sequence to list of where each new symbol start (the topology), e.g. AAABBBBCCC -> [(0,A),(3, B)(7,C)]\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    labels : list or torch.Tensor of ints\n",
    "        List of labels.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list of torch.Tensor\n",
    "        List of tensors that represents the topology.\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(labels, list):\n",
    "        labels = torch.LongTensor(labels)\n",
    "\n",
    "    if isinstance(labels, torch.Tensor):\n",
    "        zero_tensor = torch.LongTensor([0])\n",
    "        if labels.is_cuda:\n",
    "            zero_tensor = zero_tensor.cuda()\n",
    "\n",
    "        unique, count = torch.unique_consecutive(labels, return_counts=True)\n",
    "        top_list = [torch.cat((zero_tensor, labels[0:1]))]\n",
    "        prev_count = 0\n",
    "        i = 0\n",
    "        for _ in unique.split(1):\n",
    "            if i == 0:\n",
    "                i += 1\n",
    "                continue\n",
    "            prev_count += count[i - 1]\n",
    "            top_list.append(torch.cat((prev_count.view(1), unique[i].view(1))))\n",
    "            i += 1\n",
    "        return top_list\n",
    "\n",
    "\n",
    "def is_topologies_equal(topology_a, topology_b, minimum_seqment_overlap=5):\n",
    "    \"\"\"\n",
    "    Checks whether two topologies are equal.\n",
    "    E.g. [(0,A),(3, B)(7,C)]  is the same as [(0,A),(4, B)(7,C)]\n",
    "    But not the same as [(0,A),(3, C)(7,B)]\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    topology_a : list of torch.Tensor\n",
    "        First topology. See label_list_to_topology.\n",
    "    topology_b : list of torch.Tensor\n",
    "        Second topology. See label_list_to_topology.\n",
    "    minimum_seqment_overlap : int\n",
    "        Minimum overlap between two segments to be considered equal.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bool\n",
    "        True if topologies are equal, False otherwise.\n",
    "    \"\"\"\n",
    "\n",
    "    if isinstance(topology_a[0], torch.Tensor):\n",
    "        topology_a = list([a.cpu().numpy() for a in topology_a])\n",
    "    if isinstance(topology_b[0], torch.Tensor):\n",
    "        topology_b = list([b.cpu().numpy() for b in topology_b])\n",
    "    if len(topology_a) != len(topology_b):\n",
    "        return False\n",
    "    for idx, (_position_a, label_a) in enumerate(topology_a):\n",
    "        if label_a != topology_b[idx][1]:\n",
    "            if (label_a in (1,2) and topology_b[idx][1] in (1,2)): # assume O == P\n",
    "                continue\n",
    "            else:\n",
    "                return False\n",
    "        if label_a in (3, 4, 5):\n",
    "            if idx == (len(topology_a) - 1): # it's impossible to end in 3, 4 or 5\n",
    "                return False\n",
    "            else:\n",
    "                overlap_segment_start = max(topology_a[idx][0], topology_b[idx][0])\n",
    "                overlap_segment_end = min(topology_a[idx + 1][0], topology_b[idx + 1][0])\n",
    "                    \n",
    "            if label_a == 5:\n",
    "                # Set minimum segment overlap to 3 for Beta regions\n",
    "                minimum_seqment_overlap = 3\n",
    "            if overlap_segment_end - overlap_segment_start < minimum_seqment_overlap:\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "def calculate_acc(correct, total):\n",
    "    total = total.float()\n",
    "    correct = correct.float()\n",
    "    if total == 0.0:\n",
    "        return torch.tensor(1)\n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function calls all helper function for accuracy computations above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_predictions(model, loader, loss_function, cv, experiment_file_path, device, condition = \"test\", epoch = 0):\n",
    "    # either loads an empty dict or the dict of the previous fold \n",
    "    experiment_json = json.loads(open(experiment_file_path, 'r').read())\n",
    "\n",
    "    confusion_matrix = torch.zeros((5, 7), dtype=torch.int64)\n",
    "    protein_label_actual = []\n",
    "    protein_label_prediction = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        test_batch_loss = []\n",
    "        \n",
    "        for _, batch in enumerate(loader):\n",
    "            inputs, labels, lengths, types = batch['data'], batch['labels'], batch['lengths'], batch[\"type\"]\n",
    "            inputs, labels, lengths, types = inputs.to(device), labels.to(device), lengths.to(device), types.to(device)\n",
    "            \n",
    "            output = model(inputs)\n",
    "            \n",
    "            predict_label = []\n",
    "            predict_prot_type = []\n",
    "            ground_truth_label = []\n",
    "            \n",
    "            # invalid_indices = np.stack(torch.where(labels == -1), axis = 1)\n",
    "            \n",
    "            loss = 0\n",
    "            for l in range(output.shape[0]):\n",
    "                # masking the zero-padded outputs\n",
    "                batch_output = output[l][:lengths[l]]\n",
    "                batch_labels = labels[l][:lengths[l]]\n",
    "                \n",
    "                # compute cross-entropy loss\n",
    "                loss += loss_function(batch_output, batch_labels) / output.shape[0]\n",
    "                \n",
    "                # predict labels and type for the masked outputs\n",
    "                predictions_batch_mask = batch_output.max(-1)[1]\n",
    "                predict_prot_type_batch = type_from_labels(predictions_batch_mask)\n",
    "                \n",
    "                predict_label.append(predictions_batch_mask)\n",
    "                ground_truth_label.append(batch_labels)\n",
    "                predict_prot_type.append(predict_prot_type_batch)\n",
    "                \n",
    "                # used later for the accuracy computation\n",
    "                protein_label_actual.extend(ground_truth_label)\n",
    "            \n",
    "            # go over each protein and compute accuracy\n",
    "            for idx, actual_type in enumerate(types):\n",
    "                predicted_type = predict_prot_type[idx]\n",
    "                predicted_topology = label_list_to_topology(predict_label[idx])\n",
    "                predicted_labels_for_protein = predict_label[idx]\n",
    "                \n",
    "                # convert output and label to topology sequences    \n",
    "                ground_truth_topology = label_list_to_topology(ground_truth_label[idx])\n",
    "                \n",
    "                prediction_topology_match = is_topologies_equal(ground_truth_topology, predicted_topology, 5)\n",
    "                \n",
    "                if actual_type == predicted_type:\n",
    "                    # if we guessed the type right for SP+GLOB or GLOB,\n",
    "                    # count the topology as correct\n",
    "                    if actual_type == 2 or actual_type == 3 or prediction_topology_match:\n",
    "                        confusion_matrix[actual_type][5] += 1\n",
    "                    else:\n",
    "                        confusion_matrix[actual_type][predicted_type] += 1\n",
    "                elif predicted_type == None:\n",
    "                    # add to invalid column\n",
    "                    confusion_matrix[actual_type][6] += 1\n",
    "                else:\n",
    "                    confusion_matrix[actual_type][predicted_type] += 1\n",
    "                \n",
    "                protein_label_prediction.append(predicted_labels_for_protein)\n",
    "                \n",
    "                \n",
    "            # receive loss from current batch\n",
    "            test_batch_loss.append(loss.item())\n",
    "        \n",
    "    model.train()\n",
    "    \n",
    "    type_correct_ratio = \\\n",
    "    calculate_acc(confusion_matrix[0][0] + confusion_matrix[0][5], confusion_matrix[0].sum()) + \\\n",
    "    calculate_acc(confusion_matrix[1][1] + confusion_matrix[1][5], confusion_matrix[1].sum()) + \\\n",
    "    calculate_acc(confusion_matrix[2][2] + confusion_matrix[2][5], confusion_matrix[2].sum()) + \\\n",
    "    calculate_acc(confusion_matrix[3][3] + confusion_matrix[3][5], confusion_matrix[3].sum()) + \\\n",
    "    calculate_acc(confusion_matrix[4][4] + confusion_matrix[4][5], confusion_matrix[4].sum())\n",
    "    type_accuracy = float((type_correct_ratio / 5).detach())\n",
    "\n",
    "    tm_accuracy = float(calculate_acc(confusion_matrix[0][5], confusion_matrix[0].sum()).detach())\n",
    "    sptm_accuracy = float(calculate_acc(confusion_matrix[1][5], confusion_matrix[1].sum()).detach())\n",
    "    sp_accuracy = float(calculate_acc(confusion_matrix[2][5], confusion_matrix[2].sum()).detach())\n",
    "    glob_accuracy = float(calculate_acc(confusion_matrix[3][5], confusion_matrix[3].sum()).detach())\n",
    "    beta_accuracy = float(calculate_acc(confusion_matrix[4][5], confusion_matrix[4].sum()).detach())\n",
    "    \n",
    "    topology_accuracy = sum([tm_accuracy, sptm_accuracy, sp_accuracy, glob_accuracy, beta_accuracy]) / 5\n",
    "    \n",
    "    tm_type_acc = float(calculate_acc(confusion_matrix[0][0] + confusion_matrix[0][5], confusion_matrix[0].sum()).detach())\n",
    "    tm_sp_type_acc = float(calculate_acc(confusion_matrix[1][1] + confusion_matrix[1][5], confusion_matrix[1].sum()).detach())\n",
    "    sp_type_acc = float(calculate_acc(confusion_matrix[2][2] + confusion_matrix[2][5], confusion_matrix[2].sum()).detach())\n",
    "    glob_type_acc = float(calculate_acc(confusion_matrix[3][3] + confusion_matrix[3][5], confusion_matrix[3].sum()).detach())\n",
    "    beta_type_acc = float(calculate_acc(confusion_matrix[4][4] + confusion_matrix[4][5], confusion_matrix[4].sum()).detach())\n",
    "    \n",
    "    # add data to dictionary\n",
    "    key_list = [condition, cv, epoch, 'confusion_matrix']\n",
    "    update_nested_dict(experiment_json, key_list, confusion_matrix.tolist())\n",
    "    \n",
    "    experiment_json[condition][cv][epoch].update({\n",
    "        'type': type_accuracy\n",
    "    })\n",
    "    \n",
    "    experiment_json[condition][cv][epoch].update({\n",
    "        'topology': topology_accuracy\n",
    "    })\n",
    "    \n",
    "    # Topology \n",
    "    experiment_json[condition][cv][epoch].update({\n",
    "        'tm': {\n",
    "            'type': tm_type_acc,\n",
    "            'topology': tm_accuracy\n",
    "        }\n",
    "    })\n",
    "    \n",
    "    experiment_json[condition][cv][epoch].update({\n",
    "        'sptm': {\n",
    "            'type': tm_sp_type_acc,\n",
    "            'topology': sptm_accuracy\n",
    "        }\n",
    "    })\n",
    "    \n",
    "    experiment_json[condition][cv][epoch].update({\n",
    "        'sp': {\n",
    "            'type': sp_type_acc,\n",
    "            'topology': sp_accuracy\n",
    "        }\n",
    "    })\n",
    "    \n",
    "    experiment_json[condition][cv][epoch].update({\n",
    "        'glob': {\n",
    "            'type': glob_type_acc,\n",
    "            'topology': glob_accuracy\n",
    "        }\n",
    "    })\n",
    "    \n",
    "    experiment_json[condition][cv][epoch].update({\n",
    "        'beta': {\n",
    "            'type': beta_type_acc,\n",
    "            'topology': beta_accuracy\n",
    "        }\n",
    "    })\n",
    "    \n",
    "    experiment_json[condition][cv][epoch].update({\n",
    "        'loss': np.mean(test_batch_loss)\n",
    "    })\n",
    "    \n",
    "    if condition == \"test\":\n",
    "        experiment_json[condition][cv].update({\n",
    "            \"hyperparameter\": (model.hidden_size, model.num_layers)\n",
    "        })\n",
    "    \n",
    "    open(experiment_file_path, 'w').write(json.dumps(experiment_json, indent = 4, default = custom_encoder))\n",
    "      \n",
    "    return np.mean(test_batch_loss), topology_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataset structure\n",
    "\n",
    "Create dataset to use for the dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, folder_path, split):\n",
    "        self.folder_path = folder_path\n",
    "        self.split = split\n",
    "        self.data = self.load_data()\n",
    "        \n",
    "        self.label_encoding = {'I': 0, 'O': 1, 'P': 2, 'S': 3, 'M': 4, 'B': 5}\n",
    "\n",
    "    def load_data(self):\n",
    "        file_list = [f for f in os.listdir(self.folder_path) if f.endswith('.npy')]\n",
    "        file_list.sort()  # Make sure the order is consistent\n",
    "\n",
    "        data = []\n",
    "        for file_name in file_list:\n",
    "            file_path = os.path.join(self.folder_path, file_name)\n",
    "            data.append(np.load(file_path, allow_pickle=True).item())\n",
    "\n",
    "        return data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        sample = self.data[index]\n",
    "        inputs = torch.tensor(sample['data'])\n",
    "        labels_str = sample['labels']\n",
    "\n",
    "        labels_list = [self.label_encoding[label] for label in labels_str]\n",
    "        labels_tensor = torch.tensor(labels_list, dtype=torch.long)\n",
    "        \n",
    "        p_type = type_from_labels(labels_tensor)\n",
    "\n",
    "        return {'data': inputs, 'labels': labels_tensor, 'type': p_type}\n",
    "\n",
    "def collate_fn(batch):\n",
    "    # sort the batch by sequence length in descending order\n",
    "    batch = sorted(batch, key=lambda x: len(x['data']), reverse=True)\n",
    "    \n",
    "    # pad sequences for data\n",
    "    data = [torch.tensor(sample['data']) for sample in batch]\n",
    "    padded_data = pad_sequence(data, batch_first=True, padding_value=-1)\n",
    "\n",
    "    # pad sequences for labels\n",
    "    labels = [torch.tensor(sample['labels']) for sample in batch]\n",
    "    padded_labels = pad_sequence(labels, batch_first=True, padding_value=-1)\n",
    "    \n",
    "    # pack the padded sequences for data\n",
    "    lengths = torch.tensor([len(seq) for seq in data])\n",
    "\n",
    "    types = torch.tensor([sample[\"type\"] for sample in batch])\n",
    "    \n",
    "    return {'data': padded_data, 'labels': padded_labels, \"lengths\": lengths, \"type\": types} \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and validation of neural network\n",
    "\n",
    "Helper function for training and validating the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(model, trainloader, valloader, loss_function, optimizer, fold, experiment_file_path, device, num_epochs = 50, patience = 15, verbose = False):\n",
    "\n",
    "    model.train()\n",
    "    \n",
    "    early_stopping = EarlyStopping(patience=patience, verbose=True, path = f\"best_model_{model.hidden_size}_{model.num_layers}.pt\")\n",
    "    train_loss = []\n",
    "    valid_loss = []\n",
    "    top_acc = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        for _, batch in enumerate(trainloader):\n",
    "            inputs, labels, lengths, types = batch['data'], batch['labels'], batch['lengths'], batch[\"type\"]\n",
    "            inputs, labels, lengths, types = inputs.to(device), labels.to(device), lengths.to(device), types.to(device)\n",
    "            \n",
    "            # receive output from rnn\n",
    "            output = model(inputs)  \n",
    "            \n",
    "            # loss = loss_function(output.permute(0, 2, 1), labels)\n",
    "            \n",
    "            loss = 0    \n",
    "            for l in range(output.shape[0]):\n",
    "                # masking the zero-padded outputs\n",
    "                batch_output = output[l][:lengths[l]]\n",
    "                batch_labels = labels[l][:lengths[l]]\n",
    "                \n",
    "                # compute cross-entropy loss\n",
    "                loss += loss_function(batch_output, batch_labels) / output.shape[0]\n",
    "            \n",
    "            # gradient update\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()  \n",
    "        \n",
    "        train_loss_epoch, _ = test_predictions(model = model, loader = trainloader, loss_function = loss_function,\n",
    "                         cv = str(fold), experiment_file_path = experiment_file_path, condition = \"train\", epoch = str(epoch),\n",
    "                         device = device)   \n",
    "\n",
    "        valid_loss_epoch, valid_top_acc = test_predictions(model = model, loader = valloader, loss_function = loss_function,\n",
    "                        cv = str(fold), experiment_file_path = experiment_file_path, condition = \"val\", epoch = str(epoch),\n",
    "                        device = device)\n",
    "        \n",
    "        # receive mean loss for this epoch\n",
    "        train_loss.append(train_loss_epoch)\n",
    "        valid_loss.append(valid_loss_epoch)\n",
    "        top_acc.append(valid_top_acc)\n",
    "        \n",
    "        # checking val loss for early stopping\n",
    "        early_stopping(valid_top_acc, model)\n",
    "        \n",
    "        if early_stopping.early_stop:\n",
    "            if verbose:\n",
    "                print(\"Early stopping, best loss: \", train_loss[-16], -early_stopping.best_score)\n",
    "            \n",
    "            return train_loss[-16], -early_stopping.best_score\n",
    "        \n",
    "        if verbose:\n",
    "            if epoch % 10 == 0:\n",
    "                print(\"training loss: \", train_loss[-1], \\\n",
    "                    \"\\t validation loss: \", valid_loss[-1],\n",
    "                    \"\\t early stop score:\", -early_stopping.best_score)\n",
    "    \n",
    "    return train_loss[-1], top_acc[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configurations to be set before cross-validating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set device to gpu if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.set_default_device(\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fbb3888c230>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# config\n",
    "k_folds = 5\n",
    "num_epochs = 100\n",
    "batch_size = 32\n",
    "loss_function = nn.CrossEntropyLoss(ignore_index = -1)\n",
    "lr = 1e-3\n",
    "tuning = [256, 256, 512, 512] # was previously [64, 128, 256, 512] but a tie between 256 and 512 was found.\n",
    "layers = [1, 2, 1, 2]\n",
    "verbose = False\n",
    "\n",
    "# run the file create_latent_dataset for full dataset and change path to \"encoder_proteins\"\n",
    "encoder_path = \"encoder_proteins_test\"\n",
    "\n",
    "experiment_file_list = []\n",
    "for i, j in zip(tuning, layers):\n",
    "    experiment_file_list.append(f\"stat_data_hs_{i}_l_{j}.json\")\n",
    "    experiment_json = {}\n",
    "    open(experiment_file_list[-1], 'w').write(json.dumps(experiment_json))\n",
    "\n",
    "# set fixed random number seed\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data and concatenate in order to create the full dataset. Serves as the prerequisite to split the data according to DeepTMHMM in the cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create cv's corresponding to deeptmhmm's\n",
    "cvs = list(range(5))\n",
    "kfolds = []\n",
    "for idx, split in enumerate(range(5)):\n",
    "    \n",
    "    # make cycling list and define train/val/test splits\n",
    "    idxs = np.asarray(list(islice(cycle(cvs), idx, idx + 5)))\n",
    "    train_idx, val_idx, test_idx = idxs[:3], idxs[3], idxs[4]\n",
    "    \n",
    "    kfolds.append((train_idx, val_idx, test_idx))\n",
    "\n",
    "# make on big concatenated dataset of all splits\n",
    "data_cvs = np.squeeze([CustomDataset(os.path.join(encoder_path, folder), 'train') for folder in ['cv0', 'cv1', 'cv2', 'cv3' , 'cv4']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin the actual analysis. Five-fold cross validation with hyperparameter-tuning and testing. JSON-files will be created. OBS: The code will take some time to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/zs/b0y2x66j1kx9mlgj_2cpj7bw0000gp/T/ipykernel_10014/518392344.py:40: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data = [torch.tensor(sample['data']) for sample in batch]\n",
      "/var/folders/zs/b0y2x66j1kx9mlgj_2cpj7bw0000gp/T/ipykernel_10014/518392344.py:44: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = [torch.tensor(sample['labels']) for sample in batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy increased (-inf --> 0.600000).  Saving model ...\n",
      "Validation accuracy increased (-inf --> 0.400000).  Saving model ...\n",
      "Validation accuracy increased (0.400000 --> 0.600000).  Saving model ...\n",
      "Validation accuracy increased (-inf --> 0.400000).  Saving model ...\n",
      "Validation accuracy increased (0.400000 --> 0.600000).  Saving model ...\n",
      "Validation accuracy increased (0.600000 --> 0.800000).  Saving model ...\n",
      "Validation accuracy increased (-inf --> 0.600000).  Saving model ...\n",
      "Validation accuracy increased (0.600000 --> 0.800000).  Saving model ...\n",
      "Validation accuracy increased (-inf --> 0.600000).  Saving model ...\n",
      "Validation accuracy increased (0.600000 --> 0.800000).  Saving model ...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 46\u001b[0m\n\u001b[1;32m     43\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model_rnn\u001b[38;5;241m.\u001b[39mparameters(), lr \u001b[38;5;241m=\u001b[39m lr)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# train and validate model\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m train_loss, valid_top_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_nn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel_rnn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtrainloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalloader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvalloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mloss_function\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mloss_function\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mfold\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mfold\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexperiment_file_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mexperiment_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m                                \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# save topology accuracies\u001b[39;00m\n\u001b[1;32m     53\u001b[0m val_acc_param[idx] \u001b[38;5;241m=\u001b[39m valid_top_acc\n",
      "Cell \u001b[0;32mIn[7], line 38\u001b[0m, in \u001b[0;36mtrain_nn\u001b[0;34m(model, trainloader, valloader, loss_function, optimizer, fold, experiment_file_path, device, num_epochs, patience, verbose)\u001b[0m\n\u001b[1;32m     32\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()  \n\u001b[1;32m     34\u001b[0m train_loss_epoch, _ \u001b[38;5;241m=\u001b[39m test_predictions(model \u001b[38;5;241m=\u001b[39m model, loader \u001b[38;5;241m=\u001b[39m trainloader, loss_function \u001b[38;5;241m=\u001b[39m loss_function,\n\u001b[1;32m     35\u001b[0m                  cv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(fold), experiment_file_path \u001b[38;5;241m=\u001b[39m experiment_file_path, condition \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m, epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(epoch),\n\u001b[1;32m     36\u001b[0m                  device \u001b[38;5;241m=\u001b[39m device)   \n\u001b[0;32m---> 38\u001b[0m valid_loss_epoch, valid_top_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtest_predictions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mvalloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_function\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mloss_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m                \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfold\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexperiment_file_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mexperiment_file_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcondition\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mval\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m                \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# receive mean loss for this epoch\u001b[39;00m\n\u001b[1;32m     43\u001b[0m train_loss\u001b[38;5;241m.\u001b[39mappend(train_loss_epoch)\n",
      "Cell \u001b[0;32mIn[5], line 13\u001b[0m, in \u001b[0;36mtest_predictions\u001b[0;34m(model, loader, loss_function, cv, experiment_file_path, device, condition, epoch)\u001b[0m\n\u001b[1;32m     10\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     11\u001b[0m test_batch_loss \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, batch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(loader):\n\u001b[1;32m     14\u001b[0m     inputs, labels, lengths, types \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m], batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m'\u001b[39m], batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlengths\u001b[39m\u001b[38;5;124m'\u001b[39m], batch[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     15\u001b[0m     inputs, labels, lengths, types \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39mto(device), labels\u001b[38;5;241m.\u001b[39mto(device), lengths\u001b[38;5;241m.\u001b[39mto(device), types\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_exam/lib/python3.9/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_exam/lib/python3.9/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_exam/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 40\u001b[0m, in \u001b[0;36mcollate_fn\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     37\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(batch, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mlen\u001b[39m(x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m]), reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# pad sequences for data\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m data \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mtensor(sample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m batch]\n\u001b[1;32m     41\u001b[0m padded_data \u001b[38;5;241m=\u001b[39m pad_sequence(data, batch_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, padding_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# pad sequences for labels\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[6], line 40\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     37\u001b[0m batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m(batch, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mlen\u001b[39m(x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m]), reverse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# pad sequences for data\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m data \u001b[38;5;241m=\u001b[39m [\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m sample \u001b[38;5;129;01min\u001b[39;00m batch]\n\u001b[1;32m     41\u001b[0m padded_data \u001b[38;5;241m=\u001b[39m pad_sequence(data, batch_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, padding_value\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# pad sequences for labels\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# k-fold cross validation\n",
    "for fold, (train_ids, val_id, test_id) in enumerate(kfolds):    \n",
    "    if verbose:\n",
    "        print(f'\\nFOLD {fold + 1}')\n",
    "        print('--------------------------------')\n",
    "    \n",
    "    # concatenates the data from the different cv's\n",
    "    training_data = np.concatenate(data_cvs[train_ids], axis = 0)\n",
    "    \n",
    "    # create weighted sampler with replacement to class balance\n",
    "    y_train = torch.tensor([prot_type[\"type\"] for prot_type in training_data])\n",
    "    \n",
    "    weight = torch.zeros(5)\n",
    "    for t in torch.unique(y_train):\n",
    "        class_sample_count = torch.tensor([len(torch.where(y_train == t)[0])])\n",
    "        weight[t] = 1. / class_sample_count\n",
    "    \n",
    "    samples_weight = torch.tensor([weight[t] for t in y_train])\n",
    "    \n",
    "    sampler = WeightedRandomSampler(samples_weight.type('torch.DoubleTensor'), len(samples_weight), replacement = True, generator = torch.Generator(device = device))\n",
    "    \n",
    "    # define data loaders for train/val/test data in this fold (collate 0 pads for same-length)\n",
    "    trainloader = DataLoader(\n",
    "                        training_data, batch_size=batch_size, collate_fn=collate_fn, drop_last = False, generator = torch.Generator(device = device), sampler = sampler)\n",
    "\n",
    "    valloader = DataLoader(data_cvs[val_id], batch_size=batch_size, shuffle=False, collate_fn=collate_fn, drop_last = False)\n",
    "    testloader = DataLoader(data_cvs[test_id], batch_size=batch_size, shuffle=False, collate_fn=collate_fn, drop_last = False)\n",
    "    \n",
    "    val_acc_param = np.zeros((len(tuning)))\n",
    "    \n",
    "    # hyperparameter tune\n",
    "    for idx, (param, layer) in enumerate(zip(tuning, layers)):\n",
    "        experiment_file_path = experiment_file_list[idx] \n",
    "        \n",
    "        if verbose:\n",
    "            print(f'\\nHIDDEN_SIZE {param}')\n",
    "            print('--------------------------------')\n",
    "        \n",
    "        # define models to be analyzed\n",
    "        model_rnn = RNN(512, param, 6, num_layer = layer)\n",
    "        model_rnn.to(device)\n",
    "        \n",
    "        optimizer = optim.Adam(model_rnn.parameters(), lr = lr)\n",
    "        \n",
    "        # train and validate model\n",
    "        train_loss, valid_top_acc = train_nn(model = model_rnn, \n",
    "                                        trainloader = trainloader, valloader = valloader,\n",
    "                                        loss_function = loss_function, optimizer = optimizer, \n",
    "                                        fold = fold, experiment_file_path = experiment_file_path, \n",
    "                                        device = device, num_epochs = num_epochs, verbose = verbose)\n",
    "        \n",
    "        # save topology accuracies\n",
    "        val_acc_param[idx] = valid_top_acc\n",
    "    \n",
    "    # test for the best model\n",
    "    best_param_idx = val_acc_param.argmax()\n",
    "    \n",
    "    best_model = RNN(512, tuning[best_param_idx], 6, layers[best_param_idx])\n",
    "    best_model.load_state_dict(torch.load(f\"best_model_{tuning[best_param_idx]}_{layers[best_param_idx]}.pt\"))\n",
    "    best_model.eval()\n",
    "    \n",
    "    experiment_file_path = experiment_file_list[best_param_idx]\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"\\nbest params for fold {fold + 1}: \", tuning[best_param_idx])  \n",
    "    \n",
    "    test_loss, test_top_acc = test_predictions(model = best_model,\n",
    "                    loader = testloader,\n",
    "                    loss_function = loss_function,\n",
    "                    cv = str(fold), experiment_file_path = experiment_file_path,\n",
    "                    device = device)\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"test loss for fold {fold + 1}: \", test_loss, \\\n",
    "            f\"\\ntest topology accuracy for fold {fold + 1}: \", test_top_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize results\n",
    "\n",
    "The following cells include some helper functions for plotting and the plotting itself of the model which performed the best in a majority of the five folds. How to interpret the plots/figures is thoroughly reviewed in the paper.\n",
    "\n",
    "REMARK: If you run the code using the encoder_proteins_test path, the plots that will be plotted are very bad due to the very very very small dataset. As there are only 9 samples in the training set and 3 in the validation set, and no guarantee that all protein types are present in the dataset (the first three were chosen from the original full dataset). Thus, if you want an actual representation of what the graphs look like, you should either run the code using the full dataset (see README) or have a look at the paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions for plot of training and validation loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fn(data, conf_int, early_stops, title, ylabel, labels):\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    for fold_data, conf_data, i in zip(data, conf_int, range(len(data))):\n",
    "        label=labels[i]\n",
    "        x = np.arange(len(fold_data))\n",
    "        plt.plot(fold_data, label=label) # label for the best model    \n",
    "        plt.fill_between(x, (fold_data - conf_data), (fold_data + conf_data), alpha = .1)\n",
    "    plt.vlines(early_stops, ymin = 0, ymax = np.max(fold_data), linestyles = \"dashed\", color = \"red\", label = \"early stop\", alpha = .3)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_stat(data, stat, conditions):\n",
    "    condition_loss = []\n",
    "    condition_conf = []\n",
    "    early_stops = []\n",
    "    for _, condition in enumerate(conditions):\n",
    "        avg_epoch_loss = []\n",
    "        conf_epoch = []\n",
    "        \n",
    "        for epoch in range(100):\n",
    "            epoch_loss_per_fold = []\n",
    "\n",
    "            for fold in data[condition]:\n",
    "                if str(epoch) in data[condition][fold].keys():\n",
    "                    epoch_loss_per_fold.append(data[condition][fold][str(epoch)][stat.lower()])\n",
    "\n",
    "            if epoch_loss_per_fold:\n",
    "                avg_epoch_loss.append(np.mean(epoch_loss_per_fold))\n",
    "                conf_epoch.append(1.96 * np.std(epoch_loss_per_fold) / np.sqrt(len(epoch_loss_per_fold)))\n",
    "        \n",
    "           \n",
    "        condition_loss.append(avg_epoch_loss)   \n",
    "        condition_conf.append(conf_epoch) \n",
    "\n",
    "    for fold in data[\"val\"]:\n",
    "        early_stops.append(np.argmax([data[\"val\"][fold][epochs][\"topology\"] for epochs in data[\"val\"][fold].keys()]))\n",
    "             \n",
    "    plot_fn(np.asarray(condition_loss), np.asarray(condition_conf), np.asarray(early_stops), stat, stat, conditions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function for training and validation accuracy plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_acc(data, conditions, stats):\n",
    "    condition_acc = []\n",
    "    condition_conf = []\n",
    "    early_stops = []\n",
    "    for _, condition in enumerate(conditions):\n",
    "        avg_epoch_acc = np.zeros((2, 100, 5))\n",
    "        conf_epoch_acc = np.zeros((2, 100, 5))\n",
    "        \n",
    "        for epoch in range(100):\n",
    "            epoch_acc_type_per_fold = [[], [], [], [], []]\n",
    "            epoch_acc_top_per_fold = [[], [], [], [], []]\n",
    "\n",
    "            for fold in data[condition]:\n",
    "                count = 0\n",
    "                if str(epoch) in data[condition][fold].keys():\n",
    "                    for i, stat in enumerate(stats):\n",
    "                        epoch_acc_type_per_fold[i].append(data[condition][fold][str(epoch)][stat.lower()][\"type\"])\n",
    "                        epoch_acc_top_per_fold[i].append(data[condition][fold][str(epoch)][stat.lower()][\"topology\"])\n",
    "                        count += 1\n",
    "\n",
    "            if epoch_acc_type_per_fold:\n",
    "                avg_epoch_acc[0, epoch, :] = np.mean(epoch_acc_type_per_fold, axis = 1)\n",
    "                avg_epoch_acc[1, epoch, :] = np.mean(epoch_acc_top_per_fold, axis = 1)\n",
    "                \n",
    "                conf_epoch_acc[0, epoch, :] = (1.96 * np.std(epoch_acc_type_per_fold, axis = 1) / np.sqrt(len(epoch_acc_type_per_fold)))\n",
    "                conf_epoch_acc[1, epoch, :] = (1.96 * np.std(epoch_acc_top_per_fold, axis = 1) / np.sqrt(len(epoch_acc_top_per_fold)))\n",
    "        \n",
    "        nans_acc = avg_epoch_acc[~np.isnan(avg_epoch_acc)].shape[0]\n",
    "        nans_conf = avg_epoch_acc[~np.isnan(avg_epoch_acc)].shape[0]\n",
    "        \n",
    "        avg_epoc_acc = avg_epoch_acc[~np.isnan(avg_epoch_acc)].reshape((2, nans_acc//(2*5), 5))\n",
    "        conf_epoch_acc = conf_epoch_acc[~np.isnan(avg_epoch_acc)].reshape((2, nans_conf//(2*5), 5))\n",
    "        \n",
    "        condition_acc.append(avg_epoc_acc)   \n",
    "        condition_conf.append(conf_epoch_acc) \n",
    "\n",
    "    for fold in data[condition]:\n",
    "        early_stops.append(np.argmax([data[\"val\"][fold][epochs][\"topology\"] for epochs in data[\"val\"][fold].keys()]))\n",
    "     \n",
    "    titles = [\"type\", \"topology\"]\n",
    "    labels = [\"train\", \"val\"]\n",
    "    colors = [\"darkred\", \"darkorange\", \"darkgreen\", \"darkviolet\", \"darkblue\"]\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    for i, train_val in enumerate(condition_acc):\n",
    "        for j, types in enumerate(train_val):\n",
    "            plt.subplot(1, 2, j + 1)\n",
    "            plt.gca().set_prop_cycle(cycler('color', colors))\n",
    "            x = np.arange(types.shape[0])\n",
    "            plt.plot(types, label = [stat + f\"_{labels[i]}\" for stat in stats], linestyle = \"dashed\" if labels[i] == \"val\" else \"solid\")\n",
    "            \n",
    "            for k, line in enumerate(types.T):\n",
    "                l_bound =  (line - condition_conf[i][j, :, k])\n",
    "                l_bound[(line - condition_conf[i][j, :, k]) < 0] = 0\n",
    "                u_bound =  (line + condition_conf[i][j, :, k])\n",
    "                u_bound[(line + condition_conf[i][j, :, k]) > 1] = 1\n",
    "                \n",
    "                plt.fill_between(x, l_bound, u_bound, alpha = .1)\n",
    "            \n",
    "            if i == 1:\n",
    "                plt.ylabel(\"accuracy\")\n",
    "                plt.xlabel(\"epoch\")\n",
    "                plt.title(f\"{titles[j]} accuracy\")\n",
    "                plt.legend(loc = \"lower left\")\n",
    "                plt.vlines(early_stops, ymin = 0, ymax = np.max(np.max(train_val, axis = 0)), linestyles = \"dashed\", color = \"red\", label = \"early stop\", alpha = .3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper function for plot of heat map (the function does say confusion matrix, but it is not exactly a textbook confusion matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion(data):\n",
    "    plot_data = np.zeros((5,7))\n",
    "    for split in data[\"test\"]:\n",
    "        confusion_matrix = data[\"test\"][split][\"0\"][\"confusion_matrix\"]\n",
    "        plot_data += confusion_matrix\n",
    "    \n",
    "    # percentage row-wise\n",
    "    plot_data = plot_data / (np.sum(plot_data, axis = 1, keepdims = True) + 1e-9)\n",
    "\n",
    "    row_labels = []\n",
    "    column_labels = []\n",
    "    for i in [\"tm\", \"sptm\", \"sp+glob\", \"glob\", \"beta\", \"topology\", \"invalid\"]: \n",
    "        row_labels.append(str(i) if i != \"topology\" and i != \"invalid\" else None)\n",
    "        column_labels.append(str(i))\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    sns.heatmap(plot_data, ax=ax, annot=True, xticklabels=column_labels, yticklabels=row_labels, fmt='.3g', robust = True)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = 0\n",
    "best_model_path = \"\"\n",
    "for idx, path in enumerate(experiment_file_list):\n",
    "    f = open(path)\n",
    "    file = json.load(f)\n",
    "    if \"test\" in file.keys() and len(file[\"test\"].keys()) > best:\n",
    "        best_model_path = path\n",
    "\n",
    "f = open(best_model_path)\n",
    "data = json.load(f)\n",
    "\n",
    "conditions = [\"train\", \"val\"]\n",
    "#Plot loss average across splits/folds\n",
    "plot_stat(data, \"loss\", conditions)\n",
    "\n",
    "#Plot total and each accuracy avarged across splits/folds\n",
    "plot_acc(data, conditions, [\"tm\", \"sptm\", \"sp\", \"glob\", \"beta\"])\n",
    "\n",
    "# Plot confusion matrix as table \n",
    "plot_confusion(data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_exam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
